# Modern Data Warehouse and Analytics Project

Welcome to the **Data Warehouse Project** repository! ğŸš€  
This project showcases a **modern data warehouse** built using **SQL Server**, covering **ETL (Extract, Transform, Load), Data Modeling, and Analytics**. Designed as a portfolio project, it follows industry best practices in data engineering and analytics.

---
## ğŸ—ï¸ Data Architecture

This project implements the **Medallion Architecture** with three structured layers:

1. **Bronze Layer**: Stores raw data ingested from multiple sources (CSV files, APIs, databases) into SQL Server.
2. **Silver Layer**: Processes and cleanses data, ensuring consistency and quality before transformation.
3. **Gold Layer**: Optimized for analytics, structured in a **Star Schema** for efficient querying and reporting.

![Data Architecture](docs/data_architecture.png)

---

## Prerequisites for Setting Up SQL Server on Docker (Mac Users)

### 1. Install Docker
Ensure you have Docker installed on your Mac. If not, download and install it from [Docker's official website](https://www.docker.com/products/docker-desktop/).

### 2. Run SQL Server in Docker
Open your terminal and run the following command to start an Azure SQL Edge container:

```sh
docker run -e "ACCEPT_EULA=1" \
    -e "MSSQL_SA_PASSWORD=MyStrongPass123" \
    -e "MSSQL_PID=Developer" \
    -e "MSSQL_USER=SA" \
    -p 1433:1433 -d --name=sql \
    mcr.microsoft.com/azure-sql-edge
```

- This will create and start a SQL Server instance in a Docker container.
- The **password** is set as `MyStrongPass123`. You can modify it in the command if needed.

### 3. Install Azure Data Studio
Download and install **Azure Data Studio** from [Microsoft's official website](https://learn.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver16).

### 4. Connect to SQL Server in Azure Data Studio
1. Open **Azure Data Studio**.
2. Click on **New Connection**.
3. Use the following credentials:
   - **Server Name:** `localhost`
   - **Authentication:** SQL Login
   - **Username:** `SA`
   - **Password:** `MyStrongPass123` (or the one you set in the Docker command)
   - **Encrypt:** `Mandatory`
   - **Trust server certificate:** `True`
   - Click on `Remember password`.
4. Finally click **Connect**.

### 5. Move Files to Docker Container (For BULK INSERT Operations)
When using a **Docker-based SQL Server**, you **cannot** directly BULK INSERT from your local machine. You need to move files into the Docker container's data folder first.

#### Steps to Move Files:

1. **Check Active Containers**
   ```sh
   docker ps
   ```
   - Note the **container name** from the output.

2. **Copy Files from Mac to Docker Container**
   ```sh
   docker cp 'file_path_in_mac' 'container_name':/var/opt/mssql/data/'file_name'
   ```
   - Replace `'file_path_in_mac'` with the full path of your local file.
   - Replace `'container_name'` with your actual container name (e.g., `sql`).
   - Replace `'file_name'` with the actual name of your data file.

3. **Access the Docker Container**
   ```sh
   docker exec -it 'container_name' bash
   ```

4. **Verify Files in the Data Folder**
   ```sh
   ls -l /var/opt/mssql/data
   ```

Repeat these steps until all required files are moved to the Docker container.

### 6. Next Steps
Once everything is set up, you can start running queries and managing your database in Azure Data Studio. ğŸ¯

Feel free to modify the password in the Docker command and Azure Data Studio settings if needed!

---

## ğŸ“– Project Overview

This project involves:

1. **ETL Pipelines**: Automating data ingestion, transformation, and loading into SQL Server.
2. **Data Modeling**: Designing **fact and dimension tables** to support analytical queries.
3. **Analytics & Reporting**: Generating SQL-based insights and dashboards.

ğŸ¯ Ideal for professionals and students in:
- **Data Engineering**
- **SQL Development**
- **ETL Pipeline Development**
- **Data Analytics**

---
## ğŸ› ï¸ Tech Stack & Tools

âœ… **Azure Data Studio** â€“ Core database for warehousing  

âœ… **Azure SQL Edge** â€“ ETL pipeline development   

âœ… **Draw.io** â€“ Data architecture and modeling diagrams

âœ… **Notion** â€“ Project Management & Task Tracking

âœ… **Docker** â€“ Containerizing and running SQL Server

---
## ğŸš€ Project Workflow

### **1ï¸âƒ£ Data Engineering (ETL Process)**
- Extracting raw data from multiple sources.
- Transforming and cleansing data to maintain integrity.
- Loading structured data into **SQL Server**.

### **2ï¸âƒ£ Data Modeling**
- Implementing **Star Schema** for analytical efficiency.
- Designing optimized fact and dimension tables.

### **3ï¸âƒ£ Analytics & Reporting**
- Writing advanced **SQL queries** for data analysis.
- Building dashboards in **Power BI/Tableau**.

---
## ğŸ“‚ Repository Structure

```
data-warehouse-project/
â”‚
â”œâ”€â”€ datasets/                           # Raw data files (ERP & CRM sources)
â”‚
â”œâ”€â”€ docs/                               # Documentation & architecture diagrams
â”‚   â”œâ”€â”€ etl.drawio                      # ETL pipeline architecture
â”‚   â”œâ”€â”€ data_architecture.drawio        # Warehouse architecture diagram
â”‚   â”œâ”€â”€ data_models.drawio              # Star schema design
â”‚   â”œâ”€â”€ naming-conventions.md           # Standard naming conventions
â”‚
â”œâ”€â”€ scripts/                            # SQL scripts for ETL and transformations
â”‚   â”œâ”€â”€ bronze/                         # Raw data ingestion scripts
â”‚   â”œâ”€â”€ silver/                         # Data cleansing and transformation scripts
â”‚   â”œâ”€â”€ gold/                           # Analytical model scripts
â”‚
â”œâ”€â”€ tests/                              # Data validation & quality checks
â”‚
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ LICENSE                             # Project license
â”œâ”€â”€ .gitignore                          # Git ignored files
â””â”€â”€ requirements.txt                    # Dependencies & setup requirements
```

---
## ğŸ“Š Business Use Cases

This data warehouse supports analytical insights such as:
- **Customer Segmentation** â€“ Identify key customer demographics.
- **Sales Performance Analysis** â€“ Evaluate trends and revenue growth.
- **Inventory Management** â€“ Optimize stock levels based on demand.

---
## ğŸ”§ Installation & Setup

1ï¸âƒ£ **Clone the repository:**  
```bash
   git clone https://github.com/StagMindVRithul/Data_Warehouse_Project_SQL.git
```

2ï¸âƒ£ **Set up SQL Server and import datasets.**

3ï¸âƒ£ **Run ETL scripts** to load and transform data.

4ï¸âƒ£ **Use Power BI/Tableau** to build interactive dashboards.

---
## ğŸ”¥ Future Enhancements

ğŸ”¹ Migrate to **Azure Synapse Analytics** for cloud scalability.  
ğŸ”¹ Automate ETL pipelines using **Apache Airflow**.  
ğŸ”¹ Optimize performance with **columnstore indexes**.  

---
## ğŸ›¡ï¸ License

This project is licensed under the [MIT License](LICENSE). Feel free to use, modify, and share with attribution.

---
## ğŸ“¢ Connect with Me

Let's collaborate! Connect with me on:

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/v-rithul-06b5632b6/)  

ğŸš€ **Happy Coding!**
